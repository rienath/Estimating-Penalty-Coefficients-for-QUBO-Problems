{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1715a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is quite obvious that the difference will not be statistically significant for all the problems tested. \n",
    "# Largely because the algorithms will give similar answers in many situations, which is expected.\n",
    "# But when the statistical difference is present (this should happen), the new algorithm will perform\n",
    "# better than the old one.\n",
    "# So we will test for every single problem and show that in some of them the difference is statistically \n",
    "# significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c219ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7875d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../Data/Produced/'\n",
    "# Import results obtained with Verma and Lewis penalty coefficients\n",
    "verma_greedy = pd.read_pickle(data_folder + 'verma_greedy_broken_constraints.pkl')\n",
    "verma_sa = pd.read_pickle(data_folder + 'verma_sa_broken_constraints.pkl')\n",
    "verma_tabu = pd.read_pickle(data_folder + 'verma_tabu_broken_constraints.pkl')\n",
    "# Import results obtained with monotone penalty coefficients (always =0)\n",
    "monotone_greedy = pd.read_pickle(data_folder + 'monotone_greedy_broken_constraints.pkl')\n",
    "monotone_sa = pd.read_pickle(data_folder + 'monotone_sa_broken_constraints.pkl')\n",
    "monotone_tabu = pd.read_pickle(data_folder + 'monotone_tabu_broken_constraints.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a9297",
   "metadata": {},
   "source": [
    "## Comparing Verma and Lewis to Monotone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecdbf104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dataframes\n",
    "flat = lambda df : df.to_numpy().flatten()\n",
    "a1, a2, a3 = flat(verma_greedy), flat(verma_sa), flat(verma_tabu)\n",
    "b1, b2, b3 = flat(monotone_greedy), flat(monotone_sa), flat(monotone_tabu)\n",
    "significance = pd.DataFrame(index=['t-statistic','p-value'])\n",
    "significance['Greedy Algorithm'] = stats.ttest_ind(a1, b1)\n",
    "significance['Simulated Annealing'] = stats.ttest_ind(a2, b2)\n",
    "significance['Tabu Search'] = stats.ttest_ind(a3, b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e39c9db",
   "metadata": {},
   "source": [
    "Negative t-statistic means that the mean of Verma and Lewis result is smaller than the mean of Monotone. Therefore, the number of broken constraints in the first is significantly smaller than in second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f9a7dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Greedy Algorithm</th>\n",
       "      <th>Simulated Annealing</th>\n",
       "      <th>Tabu Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t-statistic</th>\n",
       "      <td>-1.789983e+01</td>\n",
       "      <td>-1.904377e+01</td>\n",
       "      <td>-1.862161e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>4.949950e-60</td>\n",
       "      <td>2.233729e-66</td>\n",
       "      <td>5.102605e-64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Greedy Algorithm  Simulated Annealing   Tabu Search\n",
       "t-statistic     -1.789983e+01        -1.904377e+01 -1.862161e+01\n",
       "p-value          4.949950e-60         2.233729e-66  5.102605e-64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec272f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsc",
   "language": "python",
   "name": "bsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
